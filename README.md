# VoxAI
[![PyPI version](https://img.shields.io/pypi/v/voxai)](https://pypi.org/project/voxai/)  
[![License MIT](https://img.shields.io/pypi/l/voxai)](https://github.com/rtiwariops/voxai/blob/main/LICENSE)  

![VoxAI Logo](https://raw.githubusercontent.com/rtiwariops/voxai/main/assets/logo.png)

## üöÄ Features

- **Universal Audio Capture**  
  Record mic, system audio, or any combination via BlackHole (macOS) or equivalent loopback drivers.  
- **Manual Control**  
  Start/Stop buttons let you define exactly the boundaries of your prompt‚Äîperfect for long, multi-sentence queries.  
- **One-Shot Transcription**  
  Whisper processes the entire recording in a single call‚Äîno fragmented sentences.  
- **Live AI Streaming**  
  Gemini‚Äôs response appears token by token, just like in ChatGPT‚Äôs streaming interface.  
- **Configurable Model**  
  Swap between Gemini variants via environment (no code changes).  
- **Zero-Install UI Bootstrapping**  
  On first run `voxai` auto-installs the minimal Electron UI source‚Äîincluded in the PyPI package‚Äîso you only ever need `pip install voxai` and `voxai`.  

---

## üéØ Quickstart

## ‚öôÔ∏è Prerequisites

- **Python ‚â•3.7**  
- **Node.js ‚â•14**  
- **Electron** (global)  
  ```bash
  npm install -g electron

- **macOS Audio Loopback (BlackHole 2ch + Ladiocast)**:
    
   1. **Install BlackHole 2ch**::

       brew install blackhole-2ch

  2. **Create a Multi-Output Device**  
     - Open **Audio MIDI Setup**  
     - Click ‚Äú+‚Äù ‚Üí **Create Multi-Output Device**  
     - Check both **BlackHole 2ch** and **MacBook Pro Speakers**

  3. **Select Multi-Output Device**  
     System Preferences ‚Üí Sound ‚Üí Output ‚Üí **Multi-Output Device**

  4. **Configure Ladiocast**  
     - **Input 1**: **BlackHole 2ch** ‚Üí route to **Main**  
     - **Main Output**: **MacBook Pro Speakers**  
     - Mute other channels

  This will route all system and microphone audio into VoxAI.

## Install & Run
### 1) Install from PyPI
pip install voxai

### 2) Configure environment
cp .env.example .env

##### Edit `.env`:
GENAI_API_KEY=sk-‚Ä¶

GENAI_MODEL=gemini-1.5-flash

### 3) Launch the app
voxai

On first launch, VoxAI will automatically run npm install inside its bundled electron/ folder, then open a desktop window.

---

## üìñ Usage
Once the UI opens:

Start: Click Start to begin recording.

Speak: Listen to question`s from zoom, teams or any other tool aloud‚Äîno length limit.

Stop: Click Stop. Whisper transcribes your entire clip to the Transcript pane.

Ask AI: Click Ask AI. Gemini‚Äôs answer streams live into the Answer pane.

Copy & Share: Everything is plain text‚Äîcopy it, paste it, or feed it into your own RAG/finetuning pipeline.

---

## üéß How It Works

- **Start Recording**  
  Click **Start** to capture audio from your input device (e.g., BlackHole).

- **Stop & Transcribe**  
  Click **Stop**. Whisper transcribes and shows the full audio clip under **Transcript**.

- **Ask AI**  
  Click **Ask AI** to send the transcript to Gemini. Answers stream live in the **Answer** panel.

- **Copy & Share**  
  Output is plain text‚Äîreuse it in RAG/finetune workflows or anywhere else.

---

## üõ† Configuration

Set in `.env`:

| Variable        | Description                                | Example             |
|-----------------|--------------------------------------------|---------------------|
| `GENAI_API_KEY` | Google Generative AI (Gemini) API key      | `sk-‚Ä¶`              |
| `GENAI_MODEL`   | Gemini model to use                        | `gemini-1.5-flash`  |

See `.env.example` for reference.

---

## üõ†Ô∏è Developer Guide

### Install from source
git clone https://github.com/rtiwariops/voxai.git

cd voxai

pip install -e .

npm install -g electron

voxai

## ‚öôÔ∏è Features

- Universal Audio Capture (BlackHole, etc.)
- Manual Control for long-form Q&A
- One-Shot, Full-Clip Transcription
- Live Token-by-Token AI Streaming
- Configurable Gemini Model (`.env`)
- Electron-Based Desktop UI

---

## üìú License

MIT License ¬© 2025 Ravi (Robbie) Tiwari

Released under the MIT License.